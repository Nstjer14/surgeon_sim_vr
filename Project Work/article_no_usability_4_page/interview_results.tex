The two participants were both able to test the system. The following interview revealed that the system at present was satisfactory at simulating the scenario, but was not comprehensive enough to warrant implementation with them. They believed the interaction was sufficient, and that trainees didn't require additional features, however they both stated that several features should be available to the instructors, such as scene change and reset, interacting with procedures and progress, as well as changing the rules during play (for example by introducing emergencies).

One key point throughout the interview was realism. This was brought up many times, and the consensus was that the closer the simulation was to total realism, both with controls, models, and textures, the more it could replace or improve upon current training standards. This meant that, for example, the robot should have multiple end effectors to allow more realistic movement. The current da Vinci model has three control points and can rotate around itself which the simulated model does not. Floor, wall, and object textures, as well as lighting, also required significant work to match the real world. The console used in real RAMIS surgeries was also missing and should be included in future iterations. In addition, the robot itself should be moveable. Introducing tool ports would, together with the improved handling, allow for teaching docking and undocking in VR. Despite all this, draping the robot arms would need to be practiced at real facilities due to the need for accurate tactile feedback.

The head surgeon stated that there were limitations, but that systems such as this could be a must-have for the future of RAMIS. He talked about fully integrating the system with current simulators such as RAMIS surgeon console simulators and anaesthetic nurse simulators. The more accuracy with which these could interact, the more team training could be moved to VR instead of physical locations. This would include real-time video feeds displayed on virtual screens within the room, allowing nurse trainees to accurately communicate and act in collaboration with surgeon trainees. He believed these simulations should include whole characters, not just hands and heads as standard in the Proteus template and other VR engines.

Despite its limitations, the current version could be used to introduce medical students to RAMIS if realism was improved. An idea was that the scene could include an animation of a surgery and allow medical students to observe. The head surgeon also mentioned that, as there was no tactile feedback, the visuals in the scene had to become more realistic as trainees are used to compensating for the lack of tactile feedback with visuals. Small vibrations or objects ``clicking" into place would also improve the usability, as trainees would know when their actions were completed correctly.

Both experts agreed that the controls of the system were intuitive and that the learning curve was appropriate for their experience with VR. Observations also showed that they both learned to teleport, grab, and interact with the robot quickly, spending only a few minutes getting comfortable with moving in VR.


%Jane Petersson thought that there was no need for the system to very accurately represent the actual scenario, but that approximation was sufficient. Docking and undocking was best trained in real life at a real system, and there was no need to attempt to replicate the physics in VR. She stated, however, that tactile feedback is important in real surgeries and training, but this can only be simulated using controller vibration in HTC Vive controllers.